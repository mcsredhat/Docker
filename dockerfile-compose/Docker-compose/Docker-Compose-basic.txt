# Introduction to Docker Compose

Docker Compose is a powerful tool that simplifies working with multi-container Docker applications. Let me explain what Docker Compose is and how to use it, with Docker CLI commands included as comments above each relevant section.

## What is Docker Compose?

Docker Compose is a tool that allows you to define and run multi-container Docker applications. Instead of managing individual containers with separate Docker commands, you can use a single YAML file to configure all your application's services, networks, and volumes. This makes it easier to create reproducible development, testing, and production environments.

Key benefits of Docker Compose include:

- Defining your entire application stack in a single file
- Starting all services with a single command
- Managing container dependencies and startup order
- Creating isolated environments for different projects
- Simplifying complex container configurations

# Docker Compose Guide

## Installing Docker Compose
```bash
# Check if Docker Compose is installed
docker compose --version

# On newer Docker installations, Compose comes pre-installed as a Docker plugin
# For older versions: sudo apt-get install docker-compose-plugin (Ubuntu/Debian)
# or: sudo yum install docker-compose-plugin (RHEL/CentOS)
```

Docker Compose usually comes pre-installed with Docker Desktop for Windows and Mac. For Linux, it can be installed separately. Recent Docker versions include Compose V2 as a Docker plugin, so you can use it with `docker compose` instead of the standalone `docker-compose` command.

## Writing Your First docker-compose.yml

The `docker-compose.yml` file is the heart of Docker Compose, where you define all your services:

```yaml
# Use 'docker compose config' to validate your docker-compose.yml
version: '3.8'

services:
  # First service definition
  webapp:
    # Specify the image to use
    image: nginx:latest
    # Map ports between host and container
    ports:
      - "8080:80"
    # Mount volumes for persistent data
    volumes:
      - ./html:/usr/share/nginx/html
```

The file starts with a `version` defining which Compose file format you're using. Under `services`, you list each container that's part of your application, along with its configuration.

## Running Multiple Containers

```yaml
# Use 'docker compose up -d' to start containers in detached mode
version: '3.8'

services:
  # Web server service
  web:
    # Build from local Dockerfile
    build: ./web
    # Map container port 5000 to host port 8000
    ports:
      - "8000:5000"
    # Set environment variables
    environment:
      - DATABASE_URL=postgres://postgres:password@db:5432/app
    # Define dependency (web starts after db)
    depends_on:
      - db

  # Database service
  db:
    # Use PostgreSQL image
    image: postgres:13
    # Set environment variables
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=app
    # Create a named volume for data persistence
    volumes:
      - postgres_data:/var/lib/postgresql/data

# Define named volumes section
volumes:
  postgres_data:
```

With this configuration, you can start both containers with a single command: `docker compose up`. The `-d` flag runs them in detached mode (background).

## Stopping and Cleaning Up

```bash
# Stop and remove containers
docker compose down

# Also remove volumes
docker compose down -v

# Also remove images
docker compose down --rmi all
```

To stop all services and remove containers, networks, and (optionally) volumes, you use the `docker compose down` command. This provides a clean way to reset your environment.

## Additional Useful Commands

```bash
# View running services
docker compose ps

# View logs
docker compose logs

# Follow logs in real-time
docker compose logs -f

# Restart services
docker compose restart

# Scale a service
docker compose up --scale web=3

# Execute commands in running containers
docker compose exec web bash

---------------------------------====================================
# Docker Compose Application Demos

## Flask + PostgreSQL Docker Compose Demo

```bash
# Start entire stack
docker compose up -d

# Follow logs from all services
docker compose logs -f

# Run migrations
docker compose exec web flask db upgrade
```

```yaml
version: '3.8'

services:
  # Flask Web Application
  web:
    # Build the container using the Dockerfile in ./web directory
    build: ./web
    # Map host port 5000 to container port 5000
    ports:
      - "5000:5000"
    # Mount application code as volume for development
    volumes:
      - ./web:/app
    # Set environment variables
    environment:
      - FLASK_APP=app.py
      - FLASK_DEBUG=1
      - DATABASE_URL=postgresql://postgres:password@db:5432/flask_db
    # Wait for db to be ready before starting
    depends_on:
      - db
    # Restart policy in case of crashes
    restart: unless-stopped
    # Define custom healthcheck
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s

  # PostgreSQL Database
  db:
    # Use official PostgreSQL image
    image: postgres:13-alpine
    # Expose port for external tools (e.g., pgAdmin)
    ports:
      - "5432:5432"
    # Set environment variables
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=flask_db
    # Store database data in named volume
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # Mount initialization scripts
      - ./db/init:/docker-entrypoint-initdb.d
    # Define healthcheck
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # pgAdmin for database management (optional)
  pgadmin:
    # Use pgAdmin 4 image
    image: dpage/pgadmin4
    # Map container port 80 to host port 8080
    ports:
      - "8080:80"
    # Set environment variables
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@example.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    # Depend on database service
    depends_on:
      - db
    # Restart policy
    restart: unless-stopped

# Define named volumes for data persistence
volumes:
  postgres_data:
```

### Flask + PostgreSQL Demo Explanation

In this Flask + PostgreSQL example:

1. We define three services: a Flask web application, a PostgreSQL database, and pgAdmin for database management.

2. The web service:
   - Builds from a local Dockerfile
   - Maps port 5000 for web access
   - Mounts the application code as a volume for live development
   - Connects to the database using environment variables
   - Includes a health check to verify the application is running

3. The database service:
   - Uses the official PostgreSQL Alpine image
   - Stores data in a named volume for persistence
   - Loads initialization scripts for database setup
   - Includes a health check to verify the database is ready

4. The pgAdmin service:
   - Provides a web interface for database management
   - Maps to port 8080 for access

5. A named volume ensures database data persists between container restarts.

## WordPress + MySQL Docker Compose Demo

```bash
# Start WordPress and MySQL
docker compose up -d

# Check container status
docker compose ps

# View WordPress logs
docker compose logs wordpress

# Install a plugin
docker compose exec wordpress wp plugin install woocommerce --activate
```

```yaml
version: '3.8'

services:
  # WordPress Application
  wordpress:
    # Use official WordPress image
    image: wordpress:latest
    # Map host port 8000 to container port 80
    ports:
      - "8000:80"
    # Set required environment variables
    environment:
      - WORDPRESS_DB_HOST=db
      - WORDPRESS_DB_USER=wordpress
      - WORDPRESS_DB_PASSWORD=wordpress_password
      - WORDPRESS_DB_NAME=wordpress
      # Additional WP configuration
      - WORDPRESS_DEBUG=1
      - WORDPRESS_CONFIG_EXTRA=define('WP_MEMORY_LIMIT', '256M');
    # Mount custom themes and plugins
    volumes:
      - wordpress_data:/var/www/html
      - ./custom-themes:/var/www/html/wp-content/themes/custom
      - ./custom-plugins:/var/www/html/wp-content/plugins/custom
    # Wait for database to be ready
    depends_on:
      - db
    # Restart policy
    restart: unless-stopped
    # Define healthcheck
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/wp-admin/install.php"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # MySQL Database
  db:
    # Use MySQL image
    image: mysql:8.0
    # Set memory limits
    deploy:
      resources:
        limits:
          memory: 1G
    # Set environment variables
    environment:
      - MYSQL_DATABASE=wordpress
      - MYSQL_USER=wordpress
      - MYSQL_PASSWORD=wordpress_password
      - MYSQL_ROOT_PASSWORD=root_password
    # Store database files in named volume
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql-init:/docker-entrypoint-initdb.d
    # Define healthcheck
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "wordpress", "-pwordpress_password"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Restart policy
    restart: unless-stopped

  # phpMyAdmin for database management (optional)
  phpmyadmin:
    # Use phpMyAdmin image
    image: phpmyadmin/phpmyadmin
    # Map container port 80 to host port 8080
    ports:
      - "8080:80"
    # Set environment variables
    environment:
      - PMA_HOST=db
      - PMA_USER=root
      - PMA_PASSWORD=root_password
    # Depend on database service
    depends_on:
      - db
    # Restart policy
    restart: unless-stopped

# Define networks (optional but good practice)
networks:
  default:
    name: wordpress_network

# Define named volumes for data persistence
volumes:
  wordpress_data:
  mysql_data:
```

### WordPress + MySQL Demo Explanation

In this WordPress + MySQL example:

1. We define three services: WordPress, MySQL, and phpMyAdmin for database management.

2. The WordPress service:
   - Uses the latest official WordPress image
   - Maps port 8000 for web access
   - Connects to the MySQL database using environment variables
   - Includes custom WordPress configuration options
   - Mounts volumes for custom themes and plugins
   - Includes a health check to verify WordPress is running

3. The MySQL service:
   - Uses MySQL 8.0
   - Sets resource limits to ensure stability
   - Stores data in a named volume for persistence
   - Loads initialization scripts for database setup
   - Includes a health check to verify the database is ready

4. The phpMyAdmin service:
   - Provides a web interface for database management
   - Maps to port 8080 for access

5. Named volumes ensure both WordPress files and database data persist between container restarts.

6. We've defined a custom network for better isolation and security.

## Key Concepts of Docker Compose

1. **Services**: Each container is defined as a service in the compose file.

2. **Volumes**: Docker Compose can create and manage persistent storage volumes.

3. **Networks**: You can create custom networks for container communication.

4. **Environment Variables**: Set container configuration through environment variables.

5. **Dependencies**: Define startup order with `depends_on` to handle service dependencies.

6. **Scaling**: Easily run multiple instances of a service with `docker compose up --scale service=3`.

7. **Container Health**: Define health checks to ensure services are running correctly.

## Advanced Docker Compose Features

While these examples cover the basics, Docker Compose offers advanced features like:

- Environment variable substitution from `.env` files
- Extension fields for reusing configuration
- Deployment configuration for Docker Swarm
- Volume drivers for cloud storage
- Custom networks with specific drivers
- Resource constraints (CPU, memory)
- Secrets management for sensitive data

Docker Compose has revolutionized local development environments by making it simple to set up complex, multi-container applications with a single command. It bridges the gap between development and production, ensuring consistent environments throughout the application lifecycle.


=====================================================================
# Docker Compose: Defining and Connecting Services

Docker Compose takes container management to the next level by handling multiple interconnected containers as a unified application. Let's explore how to define services, networks, and volumes, and how to properly connect your containers together.

## Services, Networks, and Volumes

At its core, Docker Compose is built around three key concepts that form the foundation of multi-container applications:

### Services

Services represent your application's containers. Each service is defined separately in your `docker-compose.yml` file and can be built from a Dockerfile or pulled from a registry.

```bash
# List running services
docker compose ps

# Show running processes
docker compose top
```

```yaml
services:
  webapp:
    # Define which image to use
    image: nginx:alpine
    # Set container name (optional)
    container_name: my-webapp
    # Map ports from host to container
    ports:
      - "8080:80"
```

Services encapsulate everything about a container: its image, environment variables, volumes, networks, and more. They're the building blocks of your application.

### Networks

Networks enable communication between your containers. Docker Compose automatically creates a default bridge network for your application, but you can define custom networks for better isolation and security.

```bash
# List networks
docker network ls

# Inspect the default network
docker network inspect compose_default
```

```yaml
services:
  webapp:
    # ...other configuration
    # Connect to specific networks
    networks:
      - frontend
      - backend

networks:
  # Define custom frontend network
  frontend:
    # Use specific driver (bridge is default)
    driver: bridge
  # Define custom backend network
  backend:
    driver: bridge
```

The power of custom networks is that they provide isolation between different parts of your application, improving security and making it easier to reason about your system's architecture.

### Volumes

Volumes are Docker's mechanism for persistent data storage. They allow data to survive container restarts and can be shared between containers.

```bash
# List volumes
docker volume ls

# Inspect a specific volume
docker volume inspect compose_db_data
```

```yaml
services:
  database:
    image: postgres:13
    # Mount volumes for data persistence
    volumes:
      - db_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d

volumes:
  # Define named volume
  db_data:
    # Use specific driver (local is default)
    driver: local
```

Volumes ensure that your data doesn't disappear when containers are stopped, and they make it easy to share data between services when needed.

## Connecting Multiple Containers

One of the most powerful features of Docker Compose is how easily it lets containers connect to one another. Containers in the same Compose file can reference each other by service name:

```bash
# Follow logs from api service
docker compose logs -f api
```

```yaml
services:
  # Frontend service
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    # Reference API service by name in environment variables
    environment:
      - API_URL=http://api:4000
    # Connect only to frontend network
    networks:
      - frontend

  # API service
  api:
    build: ./api
    # No need to expose ports to host if only internal communication
    expose:
      - "4000"
    # Reference database by service name
    environment:
      - DATABASE_URL=mongodb://database:27017/myapp
    # Connect to both networks
    networks:
      - frontend
      - backend

  # Database service
  database:
    image: mongo:5
    # Connect only to backend network
    networks:
      - backend

# Define custom networks for isolation
networks:
  frontend:
  backend:
```

This example demonstrates network segmentation: the frontend can only communicate with the API, not directly with the database. The API acts as a middleware between frontend and backend services.

What's happening here is quite powerful—Docker's DNS resolver automatically resolves service names to their respective IP addresses. This means that the application code can simply reference other services by name, without hardcoding IP addresses.

## Using depends_on for Service Dependencies

Container startup order matters. The `depends_on` option allows you to express this dependency:

```bash
# Create containers without starting them
docker compose up --no-start

# Start services in dependency order
docker compose start
```

```yaml
services:
  api:
    build: ./api
    # Define dependencies for startup order
    depends_on:
      - database
      - redis

  database:
    image: postgres:13
    
  redis:
    image: redis:alpine
```

It's important to understand that `depends_on` only waits for containers to start, not for services to be ready. For proper application-level readiness checks, you'll need to implement proper health checking or connection retry logic in your application.

## Managing Environment Variables in Compose

Environment variables are crucial for configuration. Docker Compose offers several ways to manage them:

```bash
# View resolved configuration with variables
docker compose config
```

```yaml
services:
  webapp:
    image: myapp:latest
    # Inline environment variables
    environment:
      - NODE_ENV=production
      - API_KEY=secret_key
      
  api:
    image: myapi:latest
    # Environment variables from file
    env_file:
      - ./config/api.env
      
  database:
    image: postgres:13
    # Mix of inline and variable substitution
    environment:
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
```

You can also use a `.env` file at the root of your project for variables that apply to the entire Compose file.

For sensitive data, using a combination of `.env` files (which you would not commit to version control) and variable substitution provides a secure way to handle configuration.

## Compose File Versioning

Docker Compose has evolved over time, with different versions supporting different features:

```bash
# Check installed version
docker compose version
```

```yaml
# Compose file format version - determines available features
version: '3.8'

services:
  webapp:
    # Rest of configuration...
```

The latest versions (3.x) are compatible with both Docker Compose and Docker Swarm, while newer features appear in minor version increments (3.8, 3.9, etc.). Specifying the version ensures your Compose file uses the right set of features for your environment.

As Docker Compose evolves, newer versions offer more capabilities, such as improved health checks, rollback controls, and deployment configuration.

## Additional Useful Commands

```bash
# Build all services
docker compose build

# Pull latest images for all services
docker compose pull

# Stop all services
docker compose stop

# Remove stopped containers
docker compose rm

# View service configuration
docker compose config --services

# Scale a service
docker compose up --scale webapp=3

# Execute commands in running containers
docker compose exec webapp bash

# View resource usage
docker compose top
```

=========================================================
# MERN Stack Docker Compose Project Guide

## Project Overview

This project uses Docker Compose to orchestrate a complete MERN (MongoDB, Express, React, Node.js) stack application with the following services:

- **Frontend**: React development server with hot-reloading
- **API**: Node.js/Express backend server
- **MongoDB**: Database server with persistence
- **Mongo Express**: Web-based MongoDB administration interface

## Project Structure

```
project-root/
├── docker-compose.yml
├── frontend/
│   ├── Dockerfile.dev
│   └── [React app files]
├── backend/
│   ├── Dockerfile.dev
│   └── [Node.js app files]
└── mongo-init/
    └── [MongoDB initialization scripts]
```

## Docker Compose Commands Explained

### 1. `docker compose up -d`
**Purpose**: Start all services in detached mode

**What it does**:
- Builds Docker images for frontend and API services (if not already built)
- Creates and starts all containers defined in docker-compose.yml
- Sets up networking between services
- Creates named volumes for data persistence
- Runs containers in the background (`-d` flag = detached mode)

**Expected outcome**: All services running and accessible via their mapped ports

### 2. `docker compose logs -f`
**Purpose**: Follow logs from all running services

**What it does**:
- Displays real-time logs from all containers
- Shows color-coded output for each service
- Continues to stream new log entries (`-f` flag = follow)
- Useful for debugging and monitoring application behavior

**Use cases**:
- Monitor application startup
- Debug errors across services
- Watch API requests and database operations

### 3. `docker compose exec api npm run seed`
**Purpose**: Run database seeding script inside the API container

**What it does**:
- Executes a command inside the running `api` container
- Runs the npm script defined as `seed` in package.json
- Typically populates the database with initial/sample data
- Must be run after services are up and healthy

**Prerequisites**: 
- API container must be running
- MongoDB must be accessible
- Seed script must be defined in backend/package.json

## Step-by-Step Project Setup

### Prerequisites
- Docker and Docker Compose installed
- Project files structured as shown above
- Dockerfiles created for frontend and backend services

### Step 1: Initial Setup
```bash
# Navigate to project directory
cd your-mern-project

# Verify docker-compose.yml exists
ls docker-compose.yml
```

### Step 2: Start All Services
```bash
# Start all services in detached mode
docker compose up -d

# Expected output:
# ✓ Container mongo created
# ✓ Container api created  
# ✓ Container frontend created
# ✓ Container mongo-express created
```

### Step 3: Monitor Service Health
```bash
# Check if all services are running
docker compose ps

# Follow logs to ensure services start correctly
docker compose logs -f

# Watch for:
# - MongoDB connection successful
# - API server listening on port 4000
# - React dev server ready on port 3000
```

### Step 4: Seed Database (Optional)
```bash
# Wait for services to be healthy, then seed database
docker compose exec api npm run seed

# Expected output:
# Database seeded successfully
# Sample data inserted
```

### Step 5: Access Your Application
- **Frontend**: http://localhost:3000
- **API**: http://localhost:4000
- **MongoDB Admin**: http://localhost:8081 (admin/admin123)
- **Direct MongoDB**: localhost:27017

## Service Architecture Breakdown

### Frontend Service
- **Port**: 3000 (host) → 3000 (container)
- **Features**: Hot-reloading, development optimized
- **Environment**: Points to API at localhost:4000
- **Dependencies**: Requires API service to be running

### API Service  
- **Port**: 4000 (host) → 4000 (container)
- **Features**: Development mode with auto-restart
- **Database**: Connects to MongoDB at mongo:27017
- **Health Check**: Monitors /api/health endpoint
- **Dependencies**: Requires healthy MongoDB connection

### MongoDB Service
- **Port**: 27017 (host) → 27017 (container)
- **Persistence**: Data stored in `mongo_data` volume
- **Initialization**: Runs scripts from ./mongo-init/
- **Health Check**: Validates database connectivity

### Mongo Express Service
- **Port**: 8081 (host) → 8081 (container)
- **Purpose**: Web-based database administration
- **Access**: Username: admin, Password: admin123
- **Dependencies**: Requires healthy MongoDB connection

## Development Workflow

### Daily Development
```bash
# Start development environment
docker compose up -d

# Monitor logs during development
docker compose logs -f api frontend

# Make code changes (auto-reloading enabled)
# Test API endpoints
# Test frontend functionality
```

### Database Operations
```bash
# Seed database with sample data
docker compose exec api npm run seed

# Access MongoDB shell
docker compose exec mongo mongosh mernapp

# View database via web interface
# Open http://localhost:8081
```

### Debugging
```bash
# View logs for specific service
docker compose logs api
docker compose logs mongo

# Execute commands inside containers
docker compose exec api bash
docker compose exec mongo mongosh

# Restart specific service
docker compose restart api
```

### Cleanup
```bash
# Stop all services
docker compose down

# Stop and remove volumes (careful - deletes data!)
docker compose down -v

# Remove built images
docker compose down --rmi all
```

## Common Issues and Solutions

### Services Won't Start
- Check if ports 3000, 4000, 8081, 27017 are available
- Verify Dockerfiles exist in frontend/ and backend/
- Check docker-compose.yml syntax

### Database Connection Issues
- Wait for MongoDB health check to pass
- Verify MONGO_URI environment variable
- Check network connectivity between services

### Hot Reloading Not Working
- Ensure volume mounts are correct in docker-compose.yml
- Check file permissions in mounted directories
- Verify development Dockerfiles are configured properly

## Next Steps

1. Customize environment variables for your specific application
2. Add additional services (Redis, Nginx, etc.) as needed
3. Create production docker-compose.yml with optimized settings
4. Set up CI/CD pipeline using these Docker configurations
5. Consider adding monitoring and logging services
=========================================================
# docker compose up -d (start all services)
# docker compose logs -f (follow logs from all services)
# docker compose exec api npm run seed (run seed script)
version: '3.8'

services:
  # React Frontend
  frontend:
    # docker layer: Build from local Dockerfile
    build:
      context: ./frontend
      # docker layer: Use development Dockerfile for hot-reloading
      dockerfile: Dockerfile.dev
    # docker layer: Map container port 3000 to host port 3000
    ports:
      - "3000:3000"
    # docker layer: Mount source code for development
    volumes:
      - ./frontend:/app
      - /app/node_modules
    # docker layer: Set environment variables
    environment:
      - NODE_ENV=development
      - REACT_APP_API_URL=http://localhost:4000/api
    # docker layer: Define dependency
    depends_on:
      - api
    # docker layer: Set restart policy
    restart: unless-stopped

  # Node.js API
  api:
    # docker layer: Build from local Dockerfile
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    # docker layer: Map container port 4000 to host port 4000
    ports:
      - "4000:4000"
    # docker layer: Mount source code for development
    volumes:
      - ./backend:/app
      - /app/node_modules
    # docker layer: Set environment variables
    environment:
      - NODE_ENV=development
      - PORT=4000
      - MONGO_URI=mongodb://mongo:27017/mernapp
      - JWT_SECRET=your_jwt_secret
    # docker layer: Define dependency
    depends_on:
      mongo:
        condition: service_healthy
    # docker layer: Add healthcheck to ensure API is running properly
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    # docker layer: Set restart policy
    restart: unless-stopped

  # MongoDB Database
  mongo:
    # docker layer: Use official MongoDB image
    image: mongo:5
    # docker layer: Map database port for external tools access
    ports:
      - "27017:27017"
    # docker layer: Store data in named volume for persistence
    volumes:
      - mongo_data:/data/db
      - ./mongo-init:/docker-entrypoint-initdb.d
    # docker layer: Set environment variables
    environment:
      - MONGO_INITDB_DATABASE=mernapp
    # docker layer: Add healthcheck to ensure MongoDB is running properly
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    # docker layer: Set restart policy
    restart: unless-stopped

  # MongoDB Admin UI (optional)
  mongo-express:
    # docker layer: Use MongoDB Express image for web-based administration
    image: mongo-express
    # docker layer: Map admin interface to port 8081
    ports:
      - "8081:8081"
    # docker layer: Set environment variables
    environment:
      - ME_CONFIG_MONGODB_SERVER=mongo
      - ME_CONFIG_MONGODB_PORT=27017
      - ME_CONFIG_BASICAUTH_USERNAME=admin
      - ME_CONFIG_BASICAUTH_PASSWORD=admin123
    # docker layer: Define dependency
    depends_on:
      mongo:
        condition: service_healthy
    # docker layer: Set restart policy
    restart: unless-stopped

# Define named volumes for data persistence
volumes:
  mongo_data:
    driver: local

# Define custom networks (optional but good for understanding the architecture)
networks:
  default:
    name: mern_network
    driver: bridge
=========================================================
# Full-Stack Web Application Project Guide

## Project Overview

This project creates a **production-ready, scalable full-stack web application** using a modern containerized architecture. The application consists of multiple interconnected services working together to provide a robust web platform.

## What This Project Does

### Core Functionality
- **Web Application**: A complete web application with frontend user interface and backend API
- **User Management**: Handle user authentication, authorization, and data management
- **Content Management**: Serve static files, media uploads, and dynamic content
- **Background Processing**: Handle time-intensive tasks asynchronously
- **Task Scheduling**: Run automated tasks on schedules (reports, cleanup, notifications)
- **Caching**: Improve performance with Redis-based caching
- **Load Balancing**: Distribute traffic efficiently through Nginx reverse proxy

### Architecture Components
1. **React Frontend** - Modern, responsive user interface
2. **Django Backend** - Robust API with business logic
3. **PostgreSQL Database** - Reliable data persistence
4. **Redis Cache** - Fast data caching and message brokering
5. **Nginx Reverse Proxy** - Traffic routing and static file serving
6. **Celery Workers** - Background task processing
7. **Celery Beat** - Scheduled task management

## Project Setup Steps

### Prerequisites
- Docker and Docker Compose installed
- Basic knowledge of React, Django, and containerization
- SSL certificates (for production HTTPS)

### Step 1: Project Structure Setup
```
project-root/
├── docker-compose.yml
├── docker-compose.prod.yml
├── .env
├── nginx/
│   ├── Dockerfile
│   ├── nginx.conf
│   └── ssl/
│       ├── cert.pem
│       └── key.pem
├── frontend/
│   ├── Dockerfile
│   ├── Dockerfile.dev
│   ├── package.json
│   └── src/
├── backend/
│   ├── Dockerfile
│   ├── Dockerfile.dev
│   ├── requirements.txt
│   ├── manage.py
│   └── config/
└── README.md
```

### Step 2: Environment Configuration
Create `.env` file with required variables:
```bash
# Database Configuration
DB_PASSWORD=your_secure_db_password

# Django Configuration
DJANGO_SECRET_KEY=your_django_secret_key_here

# Optional: Additional environment variables
REDIS_PASSWORD=your_redis_password
SSL_EMAIL=your_email@example.com
```

### Step 3: Frontend Development (React)
```bash
# Navigate to frontend directory
cd frontend/

# Install dependencies
npm install

# Key packages to install:
npm install react react-dom react-router-dom axios
npm install @testing-library/react @testing-library/jest-dom

# Create Dockerfile for production build
# Create Dockerfile.dev for development with hot-reload
```

### Step 4: Backend Development (Django)
```bash
# Navigate to backend directory
cd backend/

# Install Python dependencies
pip install django djangorestframework
pip install psycopg2-binary redis celery
pip install django-cors-headers python-decouple

# Create Django project structure
django-admin startproject config .
python manage.py startapp core

# Configure settings.py for:
# - Database connection to PostgreSQL
# - Redis configuration
# - CORS settings
# - Static and media file handling
# - Celery configuration
```

### Step 5: Database Setup
```bash
# Create database models
python manage.py makemigrations

# Run initial migrations
docker compose exec -T backend python manage.py migrate

# Create superuser
docker compose exec -T backend python manage.py createsuperuser
```

### Step 6: Nginx Configuration
Create `nginx/nginx.conf`:
```nginx
upstream frontend {
    server frontend:3000;
}

upstream backend {
    server backend:8000;
}

server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;

    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;

    location / {
        proxy_pass http://frontend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    location /api/ {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    location /static/ {
        alias /var/www/static/;
    }

    location /media/ {
        alias /var/www/media/;
    }
}
```

### Step 7: Celery Configuration
In Django settings, configure Celery:
```python
# settings.py
import os
from celery import Celery

# Celery Configuration
CELERY_BROKER_URL = f'redis://{os.getenv("REDIS_HOST", "localhost")}:6379'
CELERY_RESULT_BACKEND = f'redis://{os.getenv("REDIS_HOST", "localhost")}:6379'
CELERY_ACCEPT_CONTENT = ['application/json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
```

### Step 8: Docker Images Creation
Create Dockerfiles for each service:
- **Frontend Dockerfile**: Multi-stage build for optimized production image
- **Backend Dockerfile**: Python environment with Django dependencies
- **Nginx Dockerfile**: Custom configuration with SSL support

### Step 9: Development Workflow
```bash
# Start development environment
docker compose up -d

# View logs
docker compose logs -f

# Run database migrations
docker compose exec backend python manage.py migrate

# Collect static files
docker compose exec backend python manage.py collectstatic --noinput

# Run tests
docker compose exec backend python manage.py test
docker compose exec frontend npm test
```

### Step 10: Production Deployment
```bash
# Build and start production stack
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# Monitor services
docker compose ps
docker compose logs -f nginx
```

## Key Project Tasks and Responsibilities

### Frontend Tasks
- **User Interface Development**: Create responsive, modern UI components
- **State Management**: Handle application state and user interactions
- **API Integration**: Connect to backend services via REST API
- **Authentication**: Implement user login/logout functionality
- **Performance Optimization**: Code splitting, lazy loading, caching

### Backend Tasks
- **API Development**: Create RESTful endpoints for frontend consumption
- **Database Design**: Model data relationships and migrations
- **Authentication & Authorization**: Secure API endpoints
- **Business Logic**: Implement core application functionality
- **Background Tasks**: Handle file uploads, email sending, data processing

### DevOps Tasks
- **Container Orchestration**: Manage multi-service architecture
- **Load Balancing**: Configure Nginx for optimal traffic distribution
- **SSL/TLS Setup**: Secure communication with HTTPS
- **Monitoring**: Health checks and service monitoring
- **Backup Strategy**: Database and media file backups
- **Scaling**: Horizontal scaling of services as needed

### Database Tasks
- **Schema Design**: Create efficient database structure
- **Data Migration**: Handle schema changes and data updates
- **Performance Tuning**: Optimize queries and indexing
- **Backup & Recovery**: Ensure data persistence and recovery

### Security Tasks
- **Environment Variables**: Secure sensitive configuration
- **Network Isolation**: Proper service communication
- **Access Control**: Implement proper authentication/authorization
- **SSL Configuration**: Secure data transmission
- **Regular Updates**: Keep dependencies and images updated

## Expected Outcomes

Upon completion, this project delivers:
- **Scalable Architecture**: Can handle increasing traffic and data
- **Production-Ready**: Suitable for real-world deployment
- **Maintainable Codebase**: Well-structured, documented, and testable
- **Security Compliant**: Follows security best practices
- **Performance Optimized**: Fast loading times and efficient resource usage
- **Monitoring Capable**: Health checks and logging for operations

This project serves as a comprehensive template for building modern, containerized web applications suitable for both development and production environments.


============================================================
# docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d (start production stack)
# docker compose exec -T backend python manage.py migrate (run migrations)
# docker compose exec -T backend python manage.py collectstatic --noinput (collect static files)
version: '3.8'

services:
  # Nginx for Frontend Static Files and API Reverse Proxy
  nginx:
    # docker layer: Build custom Nginx image with configuration
    build:
      context: ./nginx
      dockerfile: Dockerfile
    # docker layer: Map ports for HTTP and HTTPS
    ports:
      - "80:80"
      - "443:443"
    # docker layer: Mount SSL certificates
    volumes:
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - static_files:/var/www/static:ro
      - media_files:/var/www/media:ro
    # docker layer: Depend on both frontend and backend services
    depends_on:
      frontend:
        condition: service_started
      backend:
        condition: service_healthy
    # docker layer: Set restart policy
    restart: always

  # React Frontend
  frontend:
    # docker layer: Build from local Dockerfile
    build:
      context: ./frontend
      # docker layer: Use build arguments for configuration
      args:
        - API_URL=https://api.example.com
    # docker layer: Expose port for Nginx service
    expose:
      - "3000"
    # docker layer: Set environment variables
    environment:
      - NODE_ENV=production
    # docker layer: Define dependency
    depends_on:
      backend:
        condition: service_healthy
    # docker layer: Add healthcheck for frontend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    # docker layer: Set restart policy
    restart: unless-stopped

  # Django Backend API
  backend:
    # docker layer: Build from local Dockerfile
    build:
      context: ./backend
    # docker layer: Expose port for internal services
    expose:
      - "8000"
    # docker layer: Mount volumes for persistent data
    volumes:
      - static_files:/app/static
      - media_files:/app/media
    # docker layer: Set environment variables
    environment:
      - DEBUG=0
      - SECRET_KEY=${DJANGO_SECRET_KEY}
      - SQL_DATABASE=postgres
      - SQL_USER=postgres
      - SQL_PASSWORD=${DB_PASSWORD}
      - SQL_HOST=db
      - SQL_PORT=5432
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    # docker layer: Define dependencies
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    # docker layer: Add healthcheck to ensure backend is running properly
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # docker layer: Set restart policy
    restart: unless-stopped

  # PostgreSQL Database
  db:
    # docker layer: Use official PostgreSQL image
    image: postgres:13-alpine
    # docker layer: Map database port for external tools access (commented out for security)
    # ports:
    #   - "5432:5432"
    # docker layer: Store data in named volume for persistence
    volumes:
      - postgres_data:/var/lib/postgresql/data
    # docker layer: Set environment variables
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=postgres
    # docker layer: Add healthcheck to ensure database is running properly
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    # docker layer: Set restart policy
    restart: unless-stopped

  # Redis for Caching and Messaging
  redis:
    # docker layer: Use official Redis image
    image: redis:6-alpine
    # docker layer: Store data in named volume for persistence
    volumes:
      - redis_data:/data
    # docker layer: Add healthcheck to ensure Redis is running properly
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    # docker layer: Set restart policy
    restart: unless-stopped

  # Celery Worker for Background Tasks
  celery:
    # docker layer: Build from backend Dockerfile
    build:
      context: ./backend
    # docker layer: Override command to run Celery worker
    command: celery -A config worker -l info
    # docker layer: Store data in named volume for persistence
    volumes:
      - media_files:/app/media
    # docker layer: Set environment variables
    environment:
      - DEBUG=0
      - SECRET_KEY=${DJANGO_SECRET_KEY}
      - SQL_DATABASE=postgres
      - SQL_USER=postgres
      - SQL_PASSWORD=${DB_PASSWORD}
      - SQL_HOST=db
      - SQL_PORT=5432
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    # docker layer: Define dependencies
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    # docker layer: Add healthcheck for Celery worker
    healthcheck:
      test: ["CMD", "celery", "-A", "config", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # docker layer: Set restart policy
    restart: unless-stopped

  # Celery Beat for Scheduled Tasks
  celery-beat:
    # docker layer: Build from backend Dockerfile
    build:
      context: ./backend
    # docker layer: Override command to run Celery Beat scheduler
    command: celery -A config beat -l info
    # docker layer: Mount volume for beat schedule persistence
    volumes:
      - celery_beat_data:/app/celerybeat-schedule
    # docker layer: Set environment variables
    environment:
      - DEBUG=0
      - SECRET_KEY=${DJANGO_SECRET_KEY}
      - SQL_DATABASE=postgres
      - SQL_USER=postgres
      - SQL_PASSWORD=${DB_PASSWORD}
      - SQL_HOST=db
      - SQL_PORT=5432
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    # docker layer: Define dependencies
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    # docker layer: Add healthcheck for Celery beat
    healthcheck:
      test: ["CMD", "pgrep", "-f", "celery.*beat"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # docker layer: Set restart policy
    restart: unless-stopped

# Define named volumes for data persistence
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  static_files:
    driver: local
  media_files:
    driver: local
  celery_beat_data:
    driver: local

# Define custom networks
networks:
  default:
    name: fullstack_network
    driver: bridge